[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[project]
name = "llm-client"
version = "0.2.0"
description = "Production-ready LLM client with provider abstraction, agents, tool calling, caching, and streaming."
readme = "README.md"
requires-python = ">=3.10"
dependencies = [
  "asyncpg>=0.27.0",
  "redis>=4.2.0",
  "aiohttp==3.9.5",
  "aiofiles>=23.0",
  "blake3>=0.4",
  "python-dotenv>=1.0",
  "openai>=1.59",
  "jsonschema>=4.22",
  "tiktoken>=0.7",
  "numpy>=1.26",
  "tqdm>=4.66",
  "six>=1.16",
]

[project.optional-dependencies]
anthropic = ["anthropic>=0.40.0"]
test = [
    "pytest>=8.0",
    "pytest-asyncio>=0.23",
    "pytest-cov>=4.1",
    "pytest-mock>=3.12",
    "respx>=0.21",
    "freezegun>=1.2",
    "httpx>=0.27",
]
all = ["anthropic>=0.40.0"]
dev = [
    "pytest>=8.0",
    "pytest-asyncio>=0.23",
    "pytest-cov>=4.1",
    "pytest-mock>=3.12",
    "respx>=0.21",
    "freezegun>=1.2",
    "httpx>=0.27",
    "anthropic>=0.40.0",
]

[tool.pytest.ini_options]
asyncio_mode = "auto"
asyncio_default_fixture_loop_scope = "function"
testpaths = ["tests"]
addopts = "-v --tb=short"
filterwarnings = [
    "ignore::DeprecationWarning",
]

[tool.coverage.run]
source = ["llm_client"]
branch = true

[tool.coverage.report]
exclude_lines = [
    "pragma: no cover",
    "if TYPE_CHECKING:",
    "raise NotImplementedError",
]

[project.urls]
Source = "https://example.com/llm-client"

[tool.setuptools.packages.find]
where = ["src"]

[tool.setuptools.package-dir]
"" = "src"
