[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[project]
name = "llm-client"
version = "0.2.0"
description = "Production-ready LLM client with provider abstraction, agents, tool calling, caching, streaming, and agent runtime orchestration."
readme = "README.md"
requires-python = ">=3.10"
dependencies = [
  "aiohttp==3.9.5",
  "aiofiles>=23.0",
  "blake3>=0.4",
  "python-dotenv>=1.0",
  "openai>=1.59",
  "jsonschema>=4.22",
  "tiktoken>=0.7",
  "numpy>=1.26",
  "tqdm>=4.66",
]

[project.optional-dependencies]
# LLM Provider extras
anthropic = ["anthropic>=0.40.0"]
google = ["google-genai>=1.0.0"]

# Performance extras
performance = ["orjson>=3.9"]

# Observability extras
telemetry = [
    "prometheus-client>=0.19",
    "opentelemetry-api>=1.20",
    "opentelemetry-sdk>=1.20",
]

# Storage backends for llm-client cache and agent-runtime persistence
postgres = ["asyncpg>=0.27.0"]
redis = ["redis>=4.2.0"]
storage = [
    "asyncpg>=0.27.0",
    "redis>=4.2.0",
]

# Queue adapters for agent-runtime
kafka = ["aiokafka>=0.10.0"]

# Agent runtime with all optional features
runtime = [
    "asyncpg>=0.27.0",
    "redis>=4.2.0",
    "opentelemetry-api>=1.20",
    "opentelemetry-sdk>=1.20",
]

# Full runtime with Kafka
runtime-full = [
    "asyncpg>=0.27.0",
    "redis>=4.2.0",
    "aiokafka>=0.10.0",
    "opentelemetry-api>=1.20",
    "opentelemetry-sdk>=1.20",
]

# Testing
test = [
    "pytest>=8.0",
    "pytest-asyncio>=0.23",
    "pytest-cov>=4.1",
    "pytest-mock>=3.12",
    "respx>=0.21",
    "freezegun>=1.2",
    "httpx>=0.27",
]

# All optional dependencies (excluding dev tools)
all = [
    "anthropic>=0.40.0",
    "google-genai>=1.0.0",
    "orjson>=3.9",
    "prometheus-client>=0.19",
    "opentelemetry-api>=1.20",
    "opentelemetry-sdk>=1.20",
    "asyncpg>=0.27.0",
    "redis>=4.2.0",
    "aiokafka>=0.10.0",
]

# Development (includes all extras and dev tools)
dev = [
    "pytest>=8.0",
    "pytest-asyncio>=0.23",
    "pytest-cov>=4.1",
    "pytest-mock>=3.12",
    "respx>=0.21",
    "freezegun>=1.2",
    "httpx>=0.27",
    "anthropic>=0.40.0",
    "google-genai>=1.0.0",
    "orjson>=3.9",
    "prometheus-client>=0.19",
    "opentelemetry-api>=1.20",
    "opentelemetry-sdk>=1.20",
    "asyncpg>=0.27.0",
    "redis>=4.2.0",
    "aiokafka>=0.10.0",
    "ruff>=0.14",
    "mypy>=1.10",
    "pre-commit>=4.0",
]

[tool.pytest.ini_options]
asyncio_mode = "auto"
asyncio_default_fixture_loop_scope = "function"
testpaths = ["tests"]
addopts = "-v --tb=short"
filterwarnings = [
    "ignore::DeprecationWarning",
]

[tool.coverage.run]
source = ["llm_client", "agent_runtime"]
branch = true

[tool.coverage.report]
exclude_lines = [
    "pragma: no cover",
    "if TYPE_CHECKING:",
    "raise NotImplementedError",
]

[tool.ruff]
target-version = "py310"
line-length = 120

[tool.ruff.lint]
select = ["E", "F", "I", "UP", "B"]

[tool.mypy]
python_version = "3.10"
ignore_missing_imports = true
warn_unused_ignores = true
warn_redundant_casts = true
warn_return_any = false
disallow_untyped_defs = false
check_untyped_defs = false

[project.urls]
Source = "https://example.com/llm-client"

[tool.setuptools.packages.find]
where = ["src"]

[tool.setuptools.package-dir]
"" = "src"
